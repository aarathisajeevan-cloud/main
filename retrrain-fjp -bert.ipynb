{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries and Models\n",
    "\n",
    "import pandas as pd #numeric calculations\n",
    "import numpy as np #numeric calculations\n",
    "import matplotlib.pyplot as plt #visualization\n",
    "import seaborn as sns #visualization\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch #deep learning\n",
    "import re #regular expressions\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import AutoTokenizer , DistilBertModel\n",
    "#DistilBertTokenizer converting raw text into a format the model can understand.  #DistilBertForSequenceClassification is a pre-trained DistilBERT model specifically designed for text classification tasks.\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score , roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12584575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "df = pd.read_excel(r\"C:\\Users\\aarat\\Desktop\\Bvoc IT\\sem6\\proj_s6\\main\\emscad_cleaned_excel.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb77dd7",
   "metadata": {},
   "source": [
    "DATA CLEANING & PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysing the dataset\n",
    "\n",
    "df.info() #to get the datatype of the data's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec5535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c55bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns #to get the column names in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d2511",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61147b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fraudulent\"].value_counts() #to get the fraudulent value counts 0 - real , 1-fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944be38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() #null values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e31d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2dc72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)\n",
    "#here print used for printing the output of both lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling the null values\n",
    "text_cols = [\"description\", \"benefits\", \"city\", \"requirements\"]\n",
    "df[text_cols] = df[text_cols].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining the contexts for easy identification for ml model\n",
    "\n",
    "text_join = [\"title\",\"description\",\"company_profile\",\"requirements\",\"benefits\"]\n",
    "df['text']= df[text_join].agg(' '.join,axis =1)\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3cbf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count plot graph for showing Real & fake values #?label it\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x = df[\"fraudulent\"],palette=[\"green\",\"red\"])\n",
    "plt.title(\"Real vs fake\")\n",
    "plt.xlabel(\"fraudulent\")\n",
    "plt.ylabel(\"text\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff5a01",
   "metadata": {},
   "source": [
    "EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09516298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Analysis\n",
    "\n",
    "#to create a correlation matrix to study the relationship btw numeric data\n",
    "numeric_df = (df.select_dtypes(include=('Int64','Float64'))).corr()#computing correlation\n",
    "print(numeric_df)\n",
    "\n",
    "#plotting the correlation matrix in heat map\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(numeric_df,cmap=\"viridis\",annot=True,fmt=\".2g\")\n",
    "plt.show()\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4df903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iqr method for outlier detection\n",
    "df[\"text_length\"] = df[\"description\"].apply(lambda x: len(str(x).split()))\n",
    "q1 = df[\"text_length\"].quantile(0.25)\n",
    "q3 = df[\"text_length\"].quantile(0.75)\n",
    "iqr = q3-q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "outliers = df[(df[\"text_length\"] < lower_bound) | (df[\"text_length\"] > upper_bound)]\n",
    "print(\"Number of outliers detected:\", outliers.shape[0])\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(df[\"text_length\"], bins=50 , color = 'yellowgreen', edgecolor = 'black' )\n",
    "plt.axvline(lower_bound, linestyle='--', label='Lower IQR Bound', color = 'violet')\n",
    "plt.axvline(upper_bound, linestyle='--', label='Upper IQR Bound', color = 'orange')\n",
    "plt.xlabel(\"Number of Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"IQR-based Outlier Detection using Histogram\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df = df[df[\"country\"]==\"US\"] #filtering only US states\n",
    "us_df =us_df[us_df[\"state\"]!='\"\"']\n",
    "print(us_df[\"state\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad4de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar chart plots that in which state in us produces the greatest number of jobs\n",
    "\n",
    "state_count = us_df[\"state\"].value_counts()\n",
    "state_count = state_count[state_count.index != '\"\"'] #removing the null values from state column\n",
    "plt.figure(figsize=(18,6))\n",
    "sns.barplot(x=state_count.index, y=state_count.values ,palette=\"plasma\",)\n",
    "plt.title(\"Top U.S. States by Number of Job Postings\")\n",
    "plt.xlabel(\"U.S. State\")\n",
    "plt.ylabel(\"Number of Jobs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dacfe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In which country has most fake jobs\n",
    "fake_df = df[df[\"fraudulent\"]==1]\n",
    "fake_df=fake_df[fake_df[\"country\"] != '\"\"']\n",
    "country_fake = fake_df[\"country\"].value_counts()\n",
    "print(country_fake)\n",
    "#converting to df\n",
    "country_fake_df = country_fake.to_frame(name=\"Fake jobs\")\n",
    "top10_countries = country_fake_df.head(10)\n",
    "\n",
    "#using bar chart for plotting it\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=top10_countries.index , y =top10_countries[\"Fake jobs\"] ,palette=\"magma\")\n",
    "\n",
    "#this loop is used for representing the value of each bar.\n",
    "for i, value in enumerate(top10_countries[\"Fake jobs\"]): #i-position of bar , value - no.of fake jobs\n",
    "    plt.text(i, value, str(value), ha=\"center\", va=\"bottom\") \n",
    "\n",
    "plt.title(\"Most fake postings in country \")\n",
    "plt.xlabel(\"No.of Fake jobs\")\n",
    "plt.show()\n",
    "#percentage case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2dcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word cloud visualization\n",
    "from wordcloud import WordCloud\n",
    "fake_jobs = \" \".join(df[df[\"fraudulent\"]==1]['description'].astype(str))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "wc = WordCloud(width = 800 , height = 400).generate(fake_jobs)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc)\n",
    "plt.title(\"Word Cloud for fake job descriptions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca180f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots to see the distribution of continous features indivdually\n",
    "\n",
    "plt.figure(figsize=(25,18))\n",
    "\n",
    "df = df[df[\"employment_type\"] != '\"\"']\n",
    "plt.subplot(3,3,1)\n",
    "sns.histplot(df[\"employment_type\"],color=\"purple\")\n",
    "plt.title(\"Employment Type Graph\")\n",
    "plt.xlabel(\"employement\")\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "df = df[df[\"required_experience\"] != '\"\"']\n",
    "plt.subplot(3,3,2)\n",
    "sns.histplot(df[\"required_experience\"],color=\"blue\")\n",
    "plt.title(\"Required Experience Graph\")\n",
    "plt.xlabel(\"Required Experience\")\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "df = df[df[\"required_education\"] != '\"\"']\n",
    "plt.subplot(3,3,3)\n",
    "sns.histplot(df[\"required_education\"],color=\"green\")\n",
    "plt.title(\"Required Education Graph\")\n",
    "plt.xlabel(\"Education\")\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83af8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in df[\"state\"]:\n",
    "    print(state)\n",
    "\n",
    "#print(df[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342485e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in df[\"country\"]:\n",
    "    print(country)\n",
    "\n",
    "#print(df[\"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8386017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [\"title\",\"description\",\"company_profile\",\"requirements\",\"benefits\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23bf00e",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING AND SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bert\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "# model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d713102",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 32\n",
    "#all_embeddings = []\n",
    "\n",
    "#model.eval()\n",
    "\n",
    "#for i in range(0, len(df), batch_size):\n",
    "#    batch_text = df[\"text\"].iloc[i:i+batch_size].tolist()\n",
    "#\n",
    "#   tokenization = tokenizer(\n",
    "#        batch_text,\n",
    "#        padding=True,\n",
    "#        truncation=True,\n",
    "#        max_length=128,\n",
    "#        return_tensors=\"pt\"\n",
    "#    )\n",
    "\n",
    " #   with torch.no_grad():\n",
    "  #     output = model(**tokenization)\n",
    "\n",
    "  #  batch_embeddings = output.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "  #  all_embeddings.append(batch_embeddings)\n",
    "\n",
    "#X = np.vstack(all_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81185baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# embeddings = output.last_hidden_state[:,0,:].numpy()\n",
    "#X = embeddings\n",
    "#y = df[\"fraudulent\"]\n",
    "#X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4689191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balancing the dataset using smote method\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote_data = SMOTE(random_state=42)\n",
    "x_imbal , y_imbal = smote_data.fit_resample(X_train_tfidf,y_train)\n",
    "print(\"/n befor smote : \",y_train.value_counts())\n",
    "print(\"/n after smote : \",y_imbal.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ea724",
   "metadata": {},
   "source": [
    "MODEL SELECTION AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ace7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING MODELS and training dataset\n",
    "\n",
    "#LOGISITIC REGRESSION,\n",
    "#For for Binary classification:0 = Real job, 1 = Fake job,\n",
    "#Studies the association btw categorical and dependent variable and set of independent variable\n",
    "logreg = LogisticRegression(max_iter=1000 , random_state=42)\n",
    "logreg.fit(X_train_tfidf , y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd830c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES\n",
    "#Used to classify job posts as Fake or Real based on text features (TF-IDF). \n",
    "#also for binary classification (0/1)\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b927ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SUPPORT VECTOR MACHINE\n",
    "#Used to separate fake and real jobs with maximum margin\n",
    "#Best with TF-IDF text features\n",
    "sup_vec = LinearSVC(max_iter=5000, random_state=42, dual=False)\n",
    "sup_vec.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a6e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST CLASSIFIER\n",
    "#Random Forest is used to classify job postings as Fake or Real by learning patterns from multiple features.\n",
    "#It takes prediction from each decision tree and based on the majority votes.\n",
    "rfc = RandomForestClassifier(n_estimators=200, random_state=42 , n_jobs=-1)\n",
    "rfc.fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58a8cb3",
   "metadata": {},
   "source": [
    "MODEL EVALUATION AND PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc8d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction and evaluation\n",
    "\n",
    "models = { \"logistic regression \" : logreg , \"Naive Bayes\" : mnb, \"Support Vector Machine\" : sup_vec , \"RandomForestClassifier\": rfc }\n",
    "\n",
    "y_pred_logreg = logreg.predict(X_test_tfidf)\n",
    "y_pred_mnb = mnb.predict(X_test_tfidf)\n",
    "y_pred_supvec = sup_vec.predict(X_test_tfidf)\n",
    "y_pred_rfc = rfc.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Logistic Regression Evaluation\")\n",
    "print(classification_report(y_test,y_pred_logreg))\n",
    "\n",
    "print(\"Naive Bayes Evaluation\")\n",
    "print(classification_report(y_test,y_pred_mnb))\n",
    "\n",
    "print(\"Support Vector Machine\")\n",
    "print(classification_report(y_test,y_pred_supvec))\n",
    "\n",
    "print(\"RandomForestClassifier\")\n",
    "print(classification_report(y_test,y_pred_rfc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
